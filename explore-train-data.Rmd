---
title: "Exploring the Train dataset"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mlogit)
library(visdat)
```

## First look at Train dataset

```{r train1}
data("Train")
train_choice_data <- Train %>% as_tibble()
train_choice_data %>% glimpse()
train_choice_data %>%
  select(where(is.numeric)) %>% 
  select(-ends_with("id")) %>% 
  vis_cor()
train_choice_data %>%
  ggplot() +
  geom_point(aes(x = price_A, y = price_B, colour = choice), alpha = 0.2) +
  theme_minimal() +
  theme(panel.grid.minor = element_blank())
```

## Look at Predictive Power Score

From https://github.com/paulvanderlaken/ppsr:

"the Predictive Power Score (PPS)...is an asymmetric, data-type-agnostic score that can detect linear or non-linear relationships between two variables. The score ranges from 0 (no predictive power) to 1 (perfect predictive power).

The general concept of PPS is useful for data exploration purposes, in the same way correlation analysis is."

```{r pps}
library(ppsr)
score_df(train_choice_data) %>% glimpse()
train_choice_data %>% 
  select(-ends_with("id")) %>% 
  visualize_pps(do_parallel = TRUE)
train_choice_data %>% 
  select(-ends_with("id")) %>% 
  visualize_correlations()

```

It's possible that the default algorithm (decision tree) isn't finding good splits. Try GLM instead.

```{r pps2}
train_choice_data %>% 
  select(-ends_with("id")) %>% 
  visualize_pps(algorithm = "glm", do_parallel = TRUE)

```

There's not much difference.

## Data management with mlogit

From https://cran.r-project.org/web/packages/mlogit/vignettes/c2.formula.data.html.

```{r}
Tr <- train_choice_data %>% 
  mutate(choiceid = row_number()) %>% 
  dfidx(shape = "wide", varying = 4:11, sep = "_",
        idx = list(c("choiceid", "id")),
        idnames = c(NA, "alt")) %>% 
  mutate(price = price/ 100 * 2.20371, time = time / 60)
Tr
```

